# MIT6.S081-2020-labs
MIT6.S081实验官方纯净源代码，原作者（Calvin Haynes）转载于MIT官方仓库git clone git://g.csail.mit.edu/xv6-labs-2020（未在GitHub上放出），在此Fork过来，感谢原作者Calvin Haynes以及MIT6.S081授课团队。

## 学习目标
- 加深对**操作系统**的理解，从更底层的视角了解并实现操作系统的相关功能
- 加深对**UNIX**的理解，熟悉UNIX的常用指令
- 加深对C/C++的理解
- 在工作简历上作为一段项目经历  

## 学习记录

- 记录自己的学习进度和心得，督促自己不断学习，打好基础，为明年（2023）找工作做好准备，冲冲冲！
- 一个分支对应一个lab，会在尽量在make grade取得满分后上传上来，每份代码都会包含详细的注释，方便自己复习。
## lab1 : Util 
- 开始日期：2022.12.04
- 完成日期：2022.12.15
- 心得：
  - 环境配置：万事开头难啊，配置实验的运行和调试环境花了我好几天的时间，由于电脑的CPU是M2，网上能够搜到的参考资料十分有限（CSDN真是个垃圾），因此踩了不少的坑，期间一度认为M2无法兼容xv6，差点放弃，好在最后还是比较完美的解决了环境配置问题。不过反过来想一下，这段折磨的经历或许可以帮助我更好地坚持下去。~~在即将放弃的时候能够提醒自己计算一下沉没成本。~~
  - 额外的小知识：我对C++的接触比较少（仅限于刷算法题），学习的也不够系统，更是没有任何C++相关的项目经历，这间接导致了我在环境配置中遇到了很多奇怪的问题，为此我不得不花费额外的时间去学习相关的知识，比如：Makefile，IDE配置和远程调试，Git。这些实用型的小知识不需要太过全面地学习，但是从0到1是必要的，之后的话可以在工作中继续熟能生巧。
  - 学习收获（以后将用知识导图展现）：第一章主要还是在"管中窥豹"，介绍了一些常用的系统调用（pipe，fork，exec，wait等等），以及基于这些系统调用实现的shell功能（IO重定向，管道）。
  - 实验收获（以后将用知识导图展现）：课程中学到的知识其实是有限且抽象的，做实验、阅读源码和参考文档会带来更多的收获，第一个lab并不难，需要注意的是：1.管道通讯中要及时关闭不必要的文件描述符。 2.大多数命令都不接受标准输入作为参数，只能直接在命令行输入参数，这会导致无法用管道命令传递参数。

## lab2 : System Calls
- 开始时间：2022.12.20
- 完成时间：2022.12.21
- 进度：
  | index  | lab| state|
    | --- | :--- | :---: |
    | 1  | Trace| √ |
    | 2 | Sysinfo| √ |
- 心得
  - 在lab1中，我在user下通过系统调用完成了几个小程序的编写，而在lab2中，我需要在kernel下完成系统调用的编写。
  - 系统调用都需要在核心态下运行，因此我需要了解：1.用户程序如何完成系统调用。 2.用户态的数据与核心态的数据如何完成交换。
    - 1.系统调用的完成：汇编代码通过使用RISC-V的ecall指令触发中断，将程序从用户态切换到内核态，并将待执行的系统调用函数编码存放在寄存器a7内。ecall会触发中断后，中断代码会将寄存器中的数据保存到当前进程的中断帧trapframe中。进入核心态之后，syscall.c会读取trapframe中保存的寄存器值，取出a7，映射到相应的系统调用函数并运行。
    - 2.数据交换：
      - 用户态 -> 核心态：用户程序会把系统调用所需的参数放在寄存器a0和a1内，然后复制到当前进程的trapframe内，系统调用直接读取trapframe的a0和a1，即可得到用户态的数据。如果用户程序传递的是一个指针，walkaddr会检查用户提供的地址是否为当前进程用户地址空间的一部分，因此程序不能欺骗内核读取其他内存。
      - 核心态 -> 用户态：用户程序会把地址作为参数传给系统调用，该地址将用来接受需要的数据。而系统调用的返回值将只作为程序是否成功运行的标志，返回值将保存在trapframe的a0中。
      - 谨慎地完成数据交换可以很好地保证操作系统的"防御性"以及程序之间的"隔离性"。
  - `任务1 Trace`
    - 描述：添加一个系统调用跟踪功能。
    - syscall中监测到trace函数后，将当前进程的proc结构体中的mask设置为待追踪的系统调用函数编号。
    - 为了跟踪子进程，需要将mask值赋给子进程。
    - 追踪到目标系统调用后，等待该系统调用返回，然后从trapframe->a0中输出他的返回值。
    - 收获：熟悉了系统调用的流程以及用户态与核心态之间数据交流的方式。
  - `任务2 Sysinfo`
    - 描述：添加一个系统调用用来收集系统的运行信息，包括空闲内存量和运行的进程数。
    - sysinfo需要将一个结构体复制回用户空间，这涉及到核心态到用户态的数据交换，需要使用argaddr()把需要返回的数据放入用户程序提供的地址内。
    - 空闲内存使用量：阅读kalloc.c代码可以发现，内存是通过链表进行保存的，所有空闲的内存保存在freelist内，通过遍历整个链表即可获得当前空闲的内存数。
    - 运行的进程数量：阅读proc.c代码可以发现，proc数组保存了所有的进程状态，遍历数组，找到所有状态不为UNUSED的进程并统计数量即可。
    - 收获：任务2使我进一步加深了核心态到用户态的数据传输方式的理解，并且还涉及到了内存管理和进程管理，这部分还没有系统地进行学习，好在题目不难，应该是在抛砖引玉吧。
## lab3 : Page Tables
- 开始时间：2022.12.27
- 完成时间：2023.01.01
- 进度：
  | index  | lab| state|
  | --- | :--- | :---: |
  | 1  | Print a page table| √ |
  | 2 | A kernel page table per process| √  |
  | 3  | Simplify copyin/copyinstr | √  |
- 心得
  - 实验目的：
    - 在用户空间，xv6会分别为每个进程提供单独的用户页表；然而在内核中，所有进程都会共享一个唯一的内核页表。每个进程的用户页表和内核页表是不同的，这样可以防止程序在用户空间修改内核数据，有利于保证隔离性。
    - 然而这种隔离策略也会给内核访问用户数据带来困难，内核接收到用户空间的虚拟地址之后，必须调用walk()，通过遍历三级页表获取对应的物理地址，然后将才能把数据传送到用户空间。
    - 使用walk()相比与直接解引用地址，不仅代码实现更复杂，运行速度也会更慢（无法利用硬件内的TLB进行快速映射）。
    - lab3的任务便是实现内核中直接解引用访问用户数据。
  - `任务1 打印页表`
    - 编写vmprint()，vmprint()接受一个页表，并输出页表内各级的PTE，将页表可视化对后续的调试有帮助。这题比较简单，模仿freewalk()对页表进行递归即可获取每级的PTE。需要注意的是PTE的前10位是flags，去掉flags后剩下的44位再在低位加上12位0（地址的格式需要对齐），即可得到下一级的物理地址了。
  - `任务2 各进程内核页表隔离`
    - 分析：要使内核能够直接解引用用户数据，直接让内核使用用户页表显然是没有用的，那么就需要在内核页表内重新建立用户页表上的映射，用户空间的虚拟地址范围为0～PLIC，内核从PLIC开始，只要保证用户空间的虚拟地址不超过PLIC就不会发生重复映射。在重新建立映射之前，首先需要实现各进程的内核页表隔离（xv6内核中所有进程共享唯一内核页表，建立新映射后无法实现隔离性）。
    - 首先需要为每个进程创建新的内核页表，页表跟进程是一一绑定的，因此显然要在proc结构体内新增一个字段用于存储新的专属内核页表。
    - 进程生成时，页表和内核栈也同时生成，需要修改allocproc()实现。
    - 进程切换时，页表也同时切换，需要修改scheduler()实现。scheduler()是进程的调度函数，切换进程之后，需要更新SATP寄存器，SATP寄存器存储着页表起始位置的物理地址。最后还要刷新TLB。
    - 进程释放时，页表和内核栈也同时释放，需要修改freeproc()。只需要释放三级内核页表，不需要释放物理内存，物理内存在用户页表的释放中已经被释放过了。
    - 至此，实现了各进程独享内核页表。
  - `任务3 重新建立映射 简化copyin/copyinstr`
    - 分析：该任务将在内核页表内建立用户空间的映射，在每一个涉及添加/修改/删除用户页表映射的地方都需要进行修改。
    - 首先编写复制映射的函数uvmcopy_u2k()，相比uvmcopy()，uvmcopy_u2k()不需要分配新的物理地址。
    - fork(), exec(), sbrk()三个函数中都涉及到用户映射的改变，因此在这三个函数中都需要使用uvmcopy_u2k()。
    - 第一个进程的创建由userinit()执行，其中并未设计以上三个函数，因此还需要在userinit()里手动进行映射，确保第一个进程的内核页表也能正确访问用户数据。
    - 当虚拟页表内存在用户数据映射时候，便能直接使用解引用访问虚拟地址了，硬件会自动将通过三级页表将虚拟地址转化为物理地址。
## lab4 : Traps
- 开始时间：2023.01.05
- 完成时间：2023.01.06
- 进度：
  | index  | lab| state|
  | --- | :--- | :---: |
  | 1  | RISC-V assembly| √ |
  | 2 | Backtrace| √ |
  | 3 | Alarm| √ |
- 心得
Trap过程梳理：
  ![Image text](https://raw.githubusercontent.com/JennyTurtles/MIT6.S081-2020-labs/traps/user/Trap.png)
- `任务1 回溯`
  - 编写backtrace()，backtrace()将获取当前栈的栈顶指针，通过读取栈中内容得到函数的调用过程。
  - 栈从高地址开始向低地址增长，sp（Stack Frame）指向栈结构（Stack Frame）的底部，fp（Frame Pointer）指向栈结构的顶部，这里的栈结构不是栈，可以把它当作栈内存放的元素。
  - 栈结构从上到下依次是：返回地址（RA）,上个栈结构的fp，寄存器，本地变量，前两个项各占8个字节（这两个项各保存一个地址，地址空间为64位）。
  - 因此，已知一个栈结构的fp（指向顶部），fp-8即为栈的返回地址，fp-16即为上一个栈结构的fp，前者即需要输出的数据，后者为调用当前函数的函数栈地址，需要进入该地址进一步递归。
  - 用户栈会占用一个页，所有栈结构的地址都在当前页内，分别使用PGROUNDDOWN和PGROUNDUP即可得到页的下界和上界，即递归的边界条件。
- `任务2 定期警报`
  - 实现一个定期的报警器，每隔一定时钟周期就运行报警函数，打印"alarm！"。
  - 分析：时钟周期的统计需要在内核中进行，而报警函数在用户空间，因此需要修改内核返回用户空间的目的地。从用户空间进入内核后，会将当前运行的位置（返回地址）存放在寄存器SEPC内，内核运行完trap代码后读取SEPC返回用户空间，因此只要将寄存器SEPC的值修改为报警函数，就可以直接在trap结束后进入报警函数。
  - 报警函数在执行的过程中会修改寄存器，这会导致原用户空间的函数执行出错，因此运行完报警函数必须返回内核恢复原寄存器内的值。具体实现：trap内修改SEPC之前把trapframe进行备份，保存在proc里面，直到报警函数运行结束，恢复备份里的trapframe。

## lab5 : Xv6 Lazy Page Allocation
- 开始时间：2023.01.09
- 完成时间：2023.01.11
- 进度：
  | index  | lab| state|
  | --- | :--- | :---: |
  | 1  | Eliminate allocation from sbrk()| √ |
  | 2 | Lazy allocation| √ |
  | 3 | Lazytests and Usertests| √ |
- 心得
  - 本次实验需要基于page fault实现lazy allocation，即：应用程序向系统请求堆内存空间时，系统延迟分配堆内存。这样做有两个好处，一是当程序一次性请求大量内存时，能够迅速地完成；二是程序申请分配的空间往往大于实际使用的空间，lazy allocation只在内存被实际用到的时候才进行内存分配，因此可以在一定程度上节约内存空间。
- `任务1 修改内存分配方式`
  - 原内存分配方式：使用sbrk(n)，n为新增/减少的内存字节数，sbrk首先会修改进程的sz（内存大小），然后调用growproc为虚拟内存分配物理空间并进行映射。
  - 要实现lazy allocation首先需要将growproc删除，阻止sbrk直接进行内存分配，正确的内存分配时刻应该为触发缺页异常时。
- `任务2 实现内存懒分配`
  - 由于在sbrk里没有为程序分配物理内存，当程序试图读写内存时，就会触发page fault并进入内核中的usertrap()。
  - 要想在usertrap中处理page fault并为正确的地址分配物理内存，必须要获取出错的虚拟内存地址和触发trap的原因。这两者可以分别从STVAL寄存器和SCAUSE寄存器获取，page fault对应的SCAUSE编号是13和15（读和写）。
  - 当SCAUSE编号为13和15时，进一步判断待分配的虚拟地址是否落在进程的用户栈内，该地址必须小于p->sz且大于p->trapframe->sp（sp指向栈的最底部）。
  - 满足以上条件即可为虚拟内存分配一个page的物理地址，分配完之后使用mappages()建立他们之间的映射。
  - 以上步骤初步完成了内存懒分配。
- `任务3 完善内存懒分配`
  - 内存懒分配会带来一系列问题，以下将一一进行处理。
  - uvmunmap：程序释放内存时默认所有内存都进行了分配（都映射到了物理地址），然而使用了懒分配以后，会有一部分尚未被使用的内存未被映射到物理地址。在释放内存的过程中，程序无法找到它们的页表，因此会触发panic。解决方法是直接删除panic让程序继续运行即可。
  - uvmcopy：fork()会把父进程的内存拷贝到子进程，拷贝的过程中uvmcopy会遍历父进程的页表，这时就会出现上文一样的问题：无法找到内存的映射，触发panic，处理方法也同上文：直接删除panic。
  - walkaddr：read()和write()同样涉及到内存的调用，然而与前面不同的是，它们是系统调用，是在内核态中运行的，内核态中无法触发page fault，因此read()和write()访问内存失败时无法进入usertrap分配新的内存。进一步分析，read()和write()会分别调用copyin()和copyout()，这两者都会使用walkaddr()查询物理地址，因此解决方法是在walkaddr内分配新的内存并建立映射，这与usertrap中的方法是类似的。

## lab6 : Copy-on-Write Fork for xv6
- 开始日期：2023.01.18
- 完成日期：2023.01.19
- 心得
  - copy-on-write (COW) 的作用是当通过fork()创建子进程的时候，不会立刻为子进程分配新的物理内存，而是让子进程的页表指向父进程的物理地址，子进程将于父进程共享物理内存，这些共享的内存会被标记为不可读。因此子进程或父进程试图写入共享的物理内存时，会触发page fault，这时应当将该物理内存进行复制并建立新的映射（设置为可读）。
  - COW使得父子进程的部分内存实现共享，从而节约物理内存。
- `任务 实现COW`
  - uvmpcopy()
    - uvmpcopy会在fork()时为子进程复制父进程的页表和物理内存，为了实现COW首先需要修改uvmpcopy的内存分配方式。
    - 删除物理内存的分配，直接把子进程的新页表映射到父进程的物理内存，并且分别将父子进程的页表的所有项目都设置为PTE_W。
    - 为了方便识别cow内存，需要将第8为PTE定义为PTE_COW，此处父子进程的页表项的PTE_COW都要设置为1。
    - 最后，所有被映射的物理内存的引用计数加一。
  - usertrap()
    - 子进程或父进程访问cow内存时由于没有写权限，会发生page fault。我们需要在usertrap中识别并处理由cow内存导致的page fault。
    - usertrap需要检查scause(13或15)和PTE_COW位是否同时符合要求，满足条件则进行后续操作。(假设子进程试图写入父进程的物理内存)
    - 创建一片新物理内存并将父进程的物理内存复制到里面，取消子进程对父进程物理内存的映射，以免发生remap，为新物理内存建立映射。
    - 最后，该片内存的引用计数减一，该操作将在kfree中完成。
  - 引用计数
    - 父子进程可能会一起共享同一片内存，对于这部分的内存需要使用引用计数，防止物理内存被删除后另一个进程无法访问的问题。
    - 在kalloc.c中声明了一个全局数组，数组长度为（PHYSTOP-KERNBASE）/ PGSIZE，物理地址除以4096即数组的索引，对应的值就是该物理地址的引用计数。
    - kfree()在释放物理内存前需要对引用计数减一，若此时引用计数等于0则释放物理内存，大于0则不释放内存。
    - kalloc()在分配物理内存时需要把引用计数初始化为1。
    - kinit()初始化物理内存时会对每片内存调用kfree，kfree中会将引用计数减一然后检测是否为0，即在进入kfree前只有引用计数为1的内存才会被初始化，因此kinit()需要设置每片内存的引用计数为1。
  - 锁
    - 所有涉及到修改引用计数的地方都需要加锁，防止进程切换导致引用计数的更新错误。
## Lab7 : Multithreading
- 开始日期：2023.01.28
- 完成日期：2023.01.29
- 心得
  - 为了实现处理器的多路复用，CPU需要频繁地进行线程的切换。线程切换的过程可以简单地概括为：旧进程从用户空间切换到内核，将寄存器的数据保存到p->context内(线程的context中)，并让调度器线程的寄存器加载到当前寄存器中；调度器线程将自己的寄存器保存到c->context(CPU的context)，然后把新线程的寄存器加载到当前寄存器，从而完成了线程的切换。
  - 不难发现，实现多线程的关键在于寄存器数据的变换。
- `实现用户级线程系统上下文切换`
  - 本实验将为用户级线程系统设计上下文切换机制，由于去掉了边界条件的判断，因此不再需要调度器线程作为中介，整个线程切换的过程得到了很大的简化。
  - struct thread
    - 添加所有的callee-save寄存器。caller-save寄存器都会被保存在线程的堆栈上，在新线程上下文恢复时可以直接从新线程的堆栈上恢复。而callee-save寄存器是由被调用函数（即thread_switch）保存的，在函数返回时这些数据会丢失，因此需要额外保存这些寄存器的内容。
    - 添加sp和ra。
  - thread_create()
    - thread_create()接受线程函数的地址，该地址需要被保存在thread结构体的ra里面。
    - sp是栈顶指针，在这里要被初始化为t->stack + STACK_SIZE。
  - thread_schedule()
    - 找到RUNNABLE线程后调用thread_switch()，将当前线程寄存器保存到全局数组内，加载新线程的寄存器。
- `实现哈希表的并行编程`
- 哈希表的桶内为链表结构，当多个线程同时对同一个链表进行写操作的时候，就会出现错误，导致数据缺失。
- 找到链表写操作的代码insert()，对其进行加锁即可。
- 链表的读操作不涉及链表的修改，因此不需要加锁。
- `屏障`
- 所有线程到达屏障时必须在此等待，直到所有其他线程也达到该点。
- 为了实现此功能需要使用睡眠锁，最后一个线程到达屏障后唤醒其他线程。
- 睡眠锁用到了条件变量，为了保证多线程修改条件变量的正确性，必须加上互斥锁，使得条件变量的修改操作在互斥锁锁定的临界区内。
## Lab8 : Locks
- 开始日期：2023.02.19
- 完成日期：2023.02.24
- ### `内存分配器优化`
  - 实验分析
    - xv6原有的内存分配方案是通过链表维护一个空闲列表，CPU所有的核心都共享这个空闲列表。当进程需要新内存的时候，会检查链表头部的页是否为空，如果不为空就将其作为自己的新空间，然后让链表头指向下一个节点。
    - 在分配新内存的过程中，会涉及多步链表的操作，如果在此期间发生中断，另一个核心同时对链表进行操纵，就会破坏空闲列表的一致性。为了避免这钟情况，就需要在对链表进行操作之前加锁，直到操作完成再释放锁。
    - 然而，使用锁会导致内存分配失去并行性，遇到频繁分配或释放内存的情况时，就会花费大量的时间在acquire上。该实验的目的是重新设计内存分配器，消除锁争用导致的时间浪费。
  - 实验思路
    - 为了提高并行度，首先想到的是提高锁的细粒度。原先的分配策略是所有CPU共用一个空闲列表和一把锁，这就导致同一时刻只有一个CPU能分配内存，为了解决这个问题，我们需要让每个CPU维护一个空闲列表，每个列表都有自己的锁。
    - kmem结构体记录了空闲列表和锁，我们为每个CPU都创建一个kmem结构体，并且把所有结构体放在数组中，然后在kinit中初始化每个CPU的锁。
    - 在kfree中，我们使用cpuid()获取当前的CPU编号，通过编号进行索引，获取当前CPU的空闲列表和锁，然后对列表进行操作。此外，为了防止中断带来的影响，需要加上push_off()和pop_off()。
    - 比较麻烦的是kalloc，由于每个CPU有各自的空闲列表，当某个CPU自己的空闲列表为空时，其他CPU可能还有空闲内存。此时，我们需要让该CPU窃取其他CPU的空闲内存。我们使用for循环遍历数组去查找是否空闲内存，找到空闲空间后加上对应CPU的锁将该空间分配给当前CPU即可。
- ### `Buffer cache并行优化`
  - 实验分析
    - xv6原先的buffer cache系统是通过一个大的循环双链表实现的，所有的CPU共享同一个链表，因此所有涉及到链表的操作都需要加锁，如果操作比较久（比如遍历整个链表寻找空闲的buffer），就会导致锁争夺，从而浪费大量的时间。
    - 要解决这个问题可以使用哈希桶，将blockno映射到对应的桶内，寻找blockno的buffer的时候先对它的桶加锁，去桶内寻找一次，没找到就尝试复用桶内空闲的buffer。
    - 如果仍未找到，则需要遍历其他的桶，从其他的桶内复用buffer。
  - 实验思路
    - 首先创建hashbuf结构体存储桶锁和头节点，基于hashbuf创建bcache，bcache中保存hashbuf数组，桶的个数设置为奇数13从而最大限度减少冲突。
    - binit()中初始化每个桶的头节点和锁，头节点的next和pre都要指向自己，表示链表为空。
    - bget()中为blockno分配buffer，具体会涉及到3个步骤
      - 在当前桶内寻找blockno
      - 在当前桶内复用blockno
      - 在其他桶内复用blockno，这里先需要获取其他桶的锁，防止出现一致性问题。为了防止死锁最好先使用holding进行判断，如果其他桶的锁已经被占用了就直接放弃获取。
    - brelse()把buf释放回对应的桶内，释放的过程中要有对应桶的锁。
    - bpin()和bunpin()也要修改为对桶加锁。
    - LRU算法
      - 为了寻找最长时间未使用的buffer，需要使用时间戳对buffer进行标记，在释放buffer的时候更新时间戳，bget()中基于时间戳选择最合适的buffer。
# lab9：Large Files
- 开始日期：2023.03.04
- 完成日期：2023.03.05
- ### `任务1 大文件读写`
  - 实验分析
    - xv6中一个inode包含12个“直接”块号和一个“间接”块号，“一级间接”块指一个最多可容纳256个块号的块，1个inode总共可以访问12+256=268个块。一个块占1024字节，因此xv6中一个inode可以访问268KB。
    - 该实验中要将一个“直接”块转换为“二级间接”块，“二级间接”块中保存256个“一级间接”块的地址，总共可以包含256*256个“直接”块。
    - 改进之后inode可以存储256*256+256+11个块，即65803KB。
  - 实验思路
    - 修改定义：NDIRECT改为11，原来的第12块作为“一级间接”块，第13块作为“二级间接”块。
    - bmap()：首先计算出bn在二级节点和一级节点中的位置，前者为bn/NINDIRECT，后者bn%NINDIRECT为。然后依次经过二级节点，一级节点，找到直接块，如果途径的节点为空的话，就使用balloc()分配一个，同时写入log。此外需要注意的是，通过bread()获取的buffer块是带锁的，必须在使用完成以后对其调用brelse()，否则buffer块很快就会被耗尽。
    - itrunc()：该函数用于释放inode及其包含的所有数据。对于二级节点，我们需要向下进行遍历，找到所有非空的直接块并清空，然后再清空对应的一级块，最后再清空二级块。
- ### `任务2 符号链接`
  - 实验分析
    - 实现xv6中的符号链接，符号链接（或软链接）是指按路径名链接的文件；当一个符号链接打开时，内核跟随该链接指向引用的文件。
  - 实验思路
    - 修改定义：在stat.h中添加T_SYMLINK用于标识文件类型为符号链接。在fcntl.h添加O_NOFOLLOW用于标识打开文件的模式是否直接打开符号链接还是割跟随符号连接。
    - sys_symlink()：创建一个符号链接涉及到磁盘的写入操作，这里首先要调用begin_op()开启事物。使用create()为符号链接创建一个inode，使用writei()将符号链接存放在inode里面。
    - sys_open()：添加对符号链接的处理。如果inode的type是T_SYMLINK且标识符没有O_NOFOLLOW，则跟随符号链接。使用readi()读出inode中的path，使用namei(path)，获取path对应的inode，如果该inode不为符号链接则结束循环返回文件标识符，否则继续跟随符号链接。
## 环境说明
- mac os 13.1
- Clion 2021
- Apple M2
